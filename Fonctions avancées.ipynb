{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctions avancées en Python\n",
    "__Durée : 1h30__\n",
    "\n",
    "Pour finir, quelques fonctions utiles pour traiter des données en Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping\n",
    "\n",
    "urllib et beautifulsoup\n",
    "\n",
    "* Récupérer des données sur une page\n",
    "* Extraire des données d'un fichier xml\n",
    " * Exemple de l'extraction des liens\n",
    "* Présentation de scrapy https://scrapy.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3 as url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "http = url.PoolManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = http.request(\"GET\",\"https://nealcaren.github.io/python-tutorials/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Données/pythonforss.txt\",\"wb\") as f:\n",
    "    f.write(request.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = bs.BeautifulSoup(request.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page.find_all(\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice collectif : Mode hackathon on\n",
    "\n",
    "Pour le moment, nous nous sommes concentrés sur Le Monde. Dans le dossier il y a les données pour Libération et La croix aussi.\n",
    "* Extraire les données des fichiers html\n",
    "* Construire un nouveau tableau avec tous les journaux\n",
    "* Poser la question de la couverture des différents journaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Faire le script qui permet de récupérer des informations sur un site (ex : le bon coin)\n",
    "#Faire un script qui permet de récupérer tous les liens d'une page html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse de réseau\n",
    "\n",
    "présentation de la librairie networkx\n",
    "\n",
    "* Comprendre la structure de réseau\n",
    "* Calculer certains indicateurs\n",
    "* Faire une sortie pour Gephi\n",
    "* Calculer des indicateurs de centralité\n",
    "* Visualiser des réseaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer un réseau de qui travaille avec qui dans la pièce. Pour cela : \n",
    "* Créer des noeuds\n",
    "* Créer des liens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_edges_from([[1,2],[1,3],[2,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculer des indicateurs de centralité"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aller plus loin\n",
    "\n",
    "* Pour gérer les gros jeux de données : Dask\n",
    "* Pour faire de la cartographie : Geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'voudr'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.snowball import FrenchStemmer\n",
    "stemmer = FrenchStemmer()\n",
    "stemmer.stem('voudrais')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
